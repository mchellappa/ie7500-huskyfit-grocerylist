{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8068ac8-5091-4b88-a9fe-7b23b3efb33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import spacy\n",
    "from spacy.language import Language\n",
    "from spacy.tokens import Span\n",
    "from spacy.matcher import PhraseMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af77c757-0a09-4e33-8c33-67af496827fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('recipe_dataset_large.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e95f2f0d-1059-4b6e-a62e-c6ccbd3af4e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2231142"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00300cfa-1801-4294-b1bc-9d38c2287ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ffd1f37-0b1f-4b6b-89a9-cb2acdb4f449",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['combined'] = data['title'] + ' ' + data['ingredients'] + ' ' + data['directions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99278a92-9a0a-416f-9813-5a74c7c34d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No-Bake Nut Cookies [\"1 c. firmly packed brown sugar\", \"1/2 c. evaporated milk\", \"1/2 tsp. vanilla\", \"1/2 c. broken nuts (pecans)\", \"2 Tbsp. butter or margarine\", \"3 1/2 c. bite size shredded rice biscuits\"] [\"In a heavy 2-quart saucepan, mix brown sugar, nuts, evaporated milk and butter or margarine.\", \"Stir over medium heat until mixture bubbles all over top.\", \"Boil and stir 5 minutes more. Take off heat.\", \"Stir in vanilla and cereal; mix well.\", \"Using 2 teaspoons, drop and shape into 30 clusters on wax paper.\", \"Let stand until firm, about 30 minutes.\"]'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['combined'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91cdbcbc-b83d-4445-96a0-96f7c83327f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = data['combined'].tolist()\n",
    "\n",
    "ner_tags = data['NER'].apply(eval).tolist()  # Convert string representations of lists to actual lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90043c1e-aa01-4a9c-ae62-ca0a1d851d8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cheese Ball [\"2 pkg. cream cheese\", \"2 c. shredded Cheddar cheese (8 oz.)\", \"1 Tbsp. chopped pimento\", \"1 Tbsp. chopped green pepper\", \"1 Tbsp. chopped onion\", \"1 tsp. lemon juice\", \"2 tsp. Worcestershire sauce\", \"dash of Tabasco sauce\", \"dash of salt\"] [\"Combine softened cream and Cheddar cheeses.\", \"Add chopped up items.\", \"Mix and add liquids last.\", \"Mix well.\", \"Roll into ball and cover with chopped nuts.\"]'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[89]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6733167a-d9cb-4372-85da-d3ec82e3c68f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cream cheese',\n",
       " 'Cheddar cheese',\n",
       " 'pimento',\n",
       " 'green pepper',\n",
       " 'onion',\n",
       " 'lemon juice',\n",
       " 'Worcestershire sauce',\n",
       " 'Tabasco sauce',\n",
       " 'salt']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_tags[89]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "baad91c2-89e5-4ae0-95b3-d98613733f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of terms\n",
    "terms = {}\n",
    "patterns = []\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "for tags in ner_tags:\n",
    "    for tag in tags:\n",
    "        if tag.lower() not in terms:\n",
    "            terms[tag.lower()] = {'label': 'INGREDIENT'}\n",
    "            patterns.append(nlp(tag.lower()))\n",
    "\n",
    "# Initialize the PhraseMatcher\n",
    "matcher = PhraseMatcher(nlp.vocab)  # nlp.vocab ~ A storage class for vocabulary and other data shared across a language\n",
    "matcher.add(\"INGREDIENT\", None, *patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3586df0c-f903-46e6-9bc0-e652e2427917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary': {}, 'problems': {}, 'attrs': {}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.analyze_pipes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac3ab8d1-2da0-4169-8815-f0b34315d0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @Language.component(\"ingredient_extractor\")\n",
    "# def ingredient_extractor(doc):\n",
    "#     matches = matcher(doc)\n",
    "#     spans = [Span(doc, start, end, label='INGREDIENT') for match_id, start, end in matches]\n",
    "\n",
    "#     # Resolve overlaps by keeping the longest span\n",
    "#     filtered_spans = spacy.util.filter_spans(spans)\n",
    "    \n",
    "#     doc.ents = filtered_spans\n",
    "#     return doc\n",
    "\n",
    "# # Add the custom component to the pipeline\n",
    "# nlp.add_pipe(\"ingredient_extractor\", last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60586022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.quantity_extractor(doc)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@Language.component(\"ingredient_extractor\")\n",
    "def ingredient_extractor(doc):\n",
    "    matches = matcher(doc)\n",
    "    spans = [Span(doc, start, end, label='INGREDIENT') for match_id, start, end in matches]\n",
    "\n",
    "    # Resolve overlaps by keeping the longest span\n",
    "    filtered_spans = spacy.util.filter_spans(spans)\n",
    "    \n",
    "    doc.ents = filtered_spans\n",
    "    return doc\n",
    "# Add the custom component to the pipeline\n",
    "nlp.add_pipe(\"ingredient_extractor\", last=True)\n",
    "\n",
    "import spacy\n",
    "from spacy.tokens import Span\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "@Language.component(\"quantity_extractor\")\n",
    "def quantity_extractor(doc):\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "    pattern = [\n",
    "        {\"LIKE_NUM\": True},  # Match numbers\n",
    "        {\"LOWER\": {\"IN\": [\"cup\", \"cups\", \"tablespoon\", \"tablespoons\", \"tsp\", \"teaspoon\", \"teaspoons\", \"oz\", \"ounce\", \"ounces\", \"pound\", \"pounds\", \"lb\", \"lbs\", \"gram\", \"grams\", \"kg\", \"kilogram\", \"kilograms\"]}}\n",
    "    ]\n",
    "    matcher.add(\"QUANTITY\", [pattern])\n",
    "    matches = matcher(doc)\n",
    "    spans = [Span(doc, start, end, label=\"QUANTITY\") for match_id, start, end in matches]\n",
    "    filtered_spans = spacy.util.filter_spans(spans)\n",
    "    \n",
    "    # Ensure no overlapping entities\n",
    "    new_ents = [ent for ent in doc.ents if ent.label_ != \"QUANTITY\"]\n",
    "    doc.ents = new_ents + filtered_spans\n",
    "    return doc\n",
    "nlp.add_pipe(\"quantity_extractor\", last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80924bca-62b8-44ae-acaf-f023d9337745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary': {'ingredient_extractor': {'assigns': [],\n",
       "   'requires': [],\n",
       "   'scores': [],\n",
       "   'retokenizes': False},\n",
       "  'quantity_extractor': {'assigns': [],\n",
       "   'requires': [],\n",
       "   'scores': [],\n",
       "   'retokenizes': False}},\n",
       " 'problems': {'ingredient_extractor': [], 'quantity_extractor': []},\n",
       " 'attrs': {}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.analyze_pipes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eea2e3cf-bb0c-4350-9826-6f805ec09317",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import DocBin\n",
    "\n",
    "train_data = [(text, {\"entities\": []}) for text in texts]\n",
    "\n",
    "for i, (text, annotations) in enumerate(train_data):\n",
    "    doc = nlp(text)\n",
    "    entities = [(ent.start_char, ent.end_char, ent.label_) for ent in doc.ents]\n",
    "    train_data[i] = (text, {\"entities\": entities})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de96b18e-1e5b-48cb-adcc-2455e851cc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_training_data(data, output_file):\n",
    "    nlp = spacy.blank(\"en\")\n",
    "    doc_bin = DocBin()\n",
    "    for text, annotations in data:\n",
    "        doc = nlp.make_doc(text)\n",
    "        ents = []\n",
    "        for start, end, label in annotations[\"entities\"]:\n",
    "            span = doc.char_span(start, end, label=label)\n",
    "            if span is not None:\n",
    "                ents.append(span)\n",
    "        doc.ents = ents\n",
    "        doc_bin.add(doc)\n",
    "    doc_bin.to_disk(output_file)\n",
    "\n",
    "save_training_data(train_data, 'training_data.spacy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cdbeb811-fd6e-4eeb-8763-afb02bcd1e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Losses: {'ner': 9461.843557978062}\n",
      "Iteration 1, Losses: {'ner': 2846.7632647632736}\n",
      "Iteration 2, Losses: {'ner': 2048.8373965888636}\n",
      "Iteration 3, Losses: {'ner': 1607.7984022433698}\n",
      "Iteration 4, Losses: {'ner': 1487.080349277643}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from spacy.training import Example\n",
    "from spacy.util import minibatch, compounding\n",
    "\n",
    "# Load the training data\n",
    "nlp = spacy.blank(\"en\")\n",
    "db = DocBin().from_disk(\"training_data.spacy\")\n",
    "docs = list(db.get_docs(nlp.vocab))\n",
    "\n",
    "# Create the NER component and add it to the pipeline\n",
    "if 'ner' not in nlp.pipe_names:\n",
    "    ner = nlp.add_pipe(\"ner\", last=True)\n",
    "\n",
    "# Add the labels to the NER component\n",
    "for _, annotations in train_data:\n",
    "    for ent in annotations.get('entities'):\n",
    "        ner.add_label(ent[2])\n",
    "\n",
    "# Disable other pipes during training\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
    "with nlp.disable_pipes(*other_pipes):\n",
    "    optimizer = nlp.begin_training()\n",
    "    for itn in range(5):  # 5 iterations\n",
    "        random.shuffle(docs)\n",
    "        losses = {}\n",
    "        batches = minibatch(docs, size=compounding(4.0, 32.0, 1.5))\n",
    "        for batch in batches:\n",
    "            for doc in batch:\n",
    "                example = Example.from_dict(doc, {\"entities\": [(ent.start_char, ent.end_char, ent.label_) for ent in doc.ents]})\n",
    "                nlp.update([example], drop=0.5, losses=losses)\n",
    "        print(f\"Iteration {itn}, Losses: {losses}\")\n",
    "\n",
    "# Save the trained model to disk\n",
    "nlp.to_disk(\"ner_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5cf65ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 cups QUANTITY\n",
      "flour INGREDIENT\n",
      "1 tablespoon QUANTITY\n",
      "sugar INGREDIENT\n"
     ]
    }
   ],
   "source": [
    "# import spacy\n",
    "# from spacy.tokens import Span\n",
    "# from spacy.matcher import Matcher\n",
    "\n",
    "# # Define a custom component for Quantity NER\n",
    "# @Language.component(\"quantity_ner\")\n",
    "# def quantity_ner(doc):\n",
    "#     matcher = Matcher(nlp.vocab)\n",
    "#     pattern = [\n",
    "#         {\"LIKE_NUM\": True},  # Match numbers\n",
    "#         {\"LOWER\": {\"IN\": [\"cup\", \"cups\", \"tablespoon\", \"tablespoons\", \"tsp\", \"teaspoon\", \"teaspoons\", \"oz\", \"ounce\", \"ounces\", \"pound\", \"pounds\", \"lb\", \"lbs\", \"gram\", \"grams\", \"kg\", \"kilogram\", \"kilograms\"]}}\n",
    "#     ]\n",
    "#     matcher.add(\"QUANTITY\", [pattern])\n",
    "#     matches = matcher(doc)\n",
    "#     spans = [Span(doc, start, end, label=\"QUANTITY\") for match_id, start, end in matches]\n",
    "#     filtered_spans = spacy.util.filter_spans(spans)\n",
    "    \n",
    "#     # Ensure no overlapping entities\n",
    "#     new_ents = [ent for ent in doc.ents if ent.label_ != \"QUANTITY\"]\n",
    "#     doc.ents = new_ents + filtered_spans\n",
    "#     return doc\n",
    "\n",
    "# if \"quantity_extractor\" not in nlp.pipe_names:\n",
    "#     nlp.add_pipe(\"quantity_extractor\", after=\"ner\")\n",
    "\n",
    "# Test the custom NER\n",
    "doc = nlp(\"Add 2 cups of flour and 1 tablespoon of sugar.\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c526825b-2ca9-4c67-b1cc-7cad473ae465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8bd5f563-8f77-4159-b853-f004870d8e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_data):\n",
    "    examples = [Example.from_dict(nlp.make_doc(text), annotations) for text, annotations in test_data]\n",
    "    scorer = model.evaluate(examples)\n",
    "    return scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea41228a-1128-439d-b2ae-ce5a09334aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'token_acc': 1.0, 'token_p': 1.0, 'token_r': 1.0, 'token_f': 1.0, 'ents_p': 0.980236171535115, 'ents_r': 0.9736403481696401, 'ents_f': 0.976927126885317, 'ents_per_type': {'INGREDIENT': {'p': 0.9771424424932879, 'r': 0.9692650975311308, 'f': 0.9731878297318782}, 'QUANTITY': {'p': 0.9987007362494587, 'r': 1.0, 'f': 0.9993499458288191}}, 'speed': 12550.41133649976}\n"
     ]
    }
   ],
   "source": [
    "evaluation_results = evaluate_model(nlp, train_data)\n",
    "print(\"Evaluation Results:\", evaluation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78c910cc-502d-4158-b96d-4fc0060ae61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model on some examples\n",
    "test_texts = \"In a heavy 2-quart saucepan, mix 2 lbs brown sugar, nuts, evaporated milk and butter or margarine. Stir over medium heat until mixture bubbles all over top. Boil and stir 5 minutes more. Take off heat. Stir in vanilla and cereal; mix well. Using 2 teaspoons, drop and shape into 30 clusters on wax paper.Let stand until firm, about 30 minutes.\"\n",
    "doc = nlp(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cffba41b-17b7-496c-bfed-49a85a72f43b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">In a heavy 2-quart saucepan, \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    mix\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">INGREDIENT</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2 lbs\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">QUANTITY</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    brown sugar\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">INGREDIENT</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    nuts\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">INGREDIENT</span>\n",
       "</mark>\n",
       ", evaporated \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    milk\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">INGREDIENT</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    butter\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">INGREDIENT</span>\n",
       "</mark>\n",
       " or \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    margarine\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">INGREDIENT</span>\n",
       "</mark>\n",
       ". Stir over medium heat until mixture bubbles all over top. Boil and stir 5 minutes more. Take off heat. Stir in \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    vanilla\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">INGREDIENT</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    cereal\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">INGREDIENT</span>\n",
       "</mark>\n",
       "; \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    mix\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">INGREDIENT</span>\n",
       "</mark>\n",
       " well. Using \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2 teaspoons\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">QUANTITY</span>\n",
       "</mark>\n",
       ", drop and shape into 30 clusters on wax paper.Let stand until firm, about 30 minutes.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "displacy.render(doc, style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b73fc503-abb6-4b9b-b811-739f9b33c94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_text = \"\"\"Peel potatoes and keep aside\n",
    "Heat oil in a wok\n",
    "Crackle mustard seeds and urad dal\n",
    "Add Kari Patta\n",
    "soute ginger garlic paste and chopped onion\n",
    "Aad potatoes and soute for 1 to 2minutes\n",
    "Add all dry masala\n",
    "Cook with lid on slow flame for 10 minutes\n",
    "Garnish with chopped coriander\n",
    "Serve hot with roti or poori\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b181f16-85a3-4051-a6a0-a582fcc04d66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Peel \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    potatoes\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">INGREDIENT</span>\n",
       "</mark>\n",
       " and keep aside<br>Heat \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    oil\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">INGREDIENT</span>\n",
       "</mark>\n",
       " in a wok<br>Crackle \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    mustard\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">INGREDIENT</span>\n",
       "</mark>\n",
       " seeds and urad dal<br>Add Kari Patta<br>soute \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ginger garlic\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">INGREDIENT</span>\n",
       "</mark>\n",
       " paste and chopped \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    onion\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">INGREDIENT</span>\n",
       "</mark>\n",
       "<br>Aad \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    potatoes\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">INGREDIENT</span>\n",
       "</mark>\n",
       " and soute for 1 to 2minutes<br>Add all dry masala<br>Cook with lid on slow flame for 10 minutes<br>Garnish with chopped coriander<br>Serve hot with roti or poori<br></div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc2 = nlp(real_text)\n",
    "\n",
    "displacy.render(doc2, style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "63011bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"ingredient\": \"mix\",\n",
      "    \"quantity\": \"\"\n",
      "  },\n",
      "  {\n",
      "    \"ingredient\": \"brown sugar\",\n",
      "    \"quantity\": \"2 lbs\"\n",
      "  },\n",
      "  {\n",
      "    \"ingredient\": \"nuts\",\n",
      "    \"quantity\": \"\"\n",
      "  },\n",
      "  {\n",
      "    \"ingredient\": \"milk\",\n",
      "    \"quantity\": \"\"\n",
      "  },\n",
      "  {\n",
      "    \"ingredient\": \"butter\",\n",
      "    \"quantity\": \"\"\n",
      "  },\n",
      "  {\n",
      "    \"ingredient\": \"margarine\",\n",
      "    \"quantity\": \"\"\n",
      "  },\n",
      "  {\n",
      "    \"ingredient\": \"vanilla\",\n",
      "    \"quantity\": \"\"\n",
      "  },\n",
      "  {\n",
      "    \"ingredient\": \"cereal\",\n",
      "    \"quantity\": \"\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "entities = []\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == \"QUANTITY\":\n",
    "        for i_ent in doc.ents:\n",
    "            if i_ent.label_ == \"INGREDIENT\" and i_ent.start == ent.end:\n",
    "                entities.append({\"ingredient\": i_ent.text, \"quantity\": ent.text})\n",
    "                break\n",
    "    elif ent.label_ == \"INGREDIENT\":\n",
    "        if not any(e[\"ingredient\"] == ent.text for e in entities):\n",
    "            entities.append({\"ingredient\": ent.text, \"quantity\": \"\"})\n",
    "\n",
    "entities_json = json.dumps(entities, indent=2)\n",
    "\n",
    "print(entities_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "365641e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'token_acc': 1.0, 'token_p': 1.0, 'token_r': 1.0, 'token_f': 1.0, 'sents_p': None, 'sents_r': None, 'sents_f': None, 'tag_acc': None, 'pos_acc': None, 'morph_acc': None, 'morph_micro_p': None, 'morph_micro_r': None, 'morph_micro_f': None, 'morph_per_feat': None, 'dep_uas': None, 'dep_las': None, 'dep_las_per_type': None, 'ents_p': 0.0, 'ents_r': 0.0, 'ents_f': 0.0, 'ents_per_type': {'INGREDIENT': {'p': 0.0, 'r': 0.0, 'f': 0.0}, 'QUANTITY': {'p': 0.0, 'r': 0.0, 'f': 0.0}}, 'cats_score': 0.0, 'cats_score_desc': 'macro F', 'cats_micro_p': 0.0, 'cats_micro_r': 0.0, 'cats_micro_f': 0.0, 'cats_macro_p': 0.0, 'cats_macro_r': 0.0, 'cats_macro_f': 0.0, 'cats_macro_auc': 0.0, 'cats_f_per_type': {}, 'cats_auc_per_type': {}}\n"
     ]
    }
   ],
   "source": [
    "from spacy.training import Example\n",
    "from spacy.scorer import Scorer\n",
    "\n",
    "def evaluate_model(model, test_data):\n",
    "\texamples = [Example.from_dict(model.make_doc(text), annotations) for text, annotations in test_data]\n",
    "\tscorer = Scorer()\n",
    "\tfor example in examples:\n",
    "\t\tmodel.update([example], sgd=None, losses={})\n",
    "\t\tscorer.score([example])  # Pass a list containing the example\n",
    "\treturn scorer.score(examples)  # Use the score method to get the evaluation results\n",
    "\n",
    "evaluation_results = evaluate_model(nlp, train_data)\n",
    "print(\"Evaluation Results:\", evaluation_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
