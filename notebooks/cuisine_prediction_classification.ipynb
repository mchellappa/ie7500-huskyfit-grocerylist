{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2de09e04-007e-4d69-a1af-12a5a9c018ad",
   "metadata": {},
   "source": [
    "# Cuisine Classification for Recipe Ingredients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a04e032-12eb-4a0f-91dc-e3ef80b599e5",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01f1a16-ad46-4626-b877-3ed8171f57d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix,roc_curve,auc\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
    "import joblib\n",
    "import ast\n",
    "from collections import Counter\n",
    "from utils.classificationutils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a7b260-ae21-445f-b6a5-55b188067e2a",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b163e1-19ac-4e52-b01f-c3d935a81a9a",
   "metadata": {},
   "source": [
    "###loading the data required for the cuisine classification project:\n",
    "\n",
    "- **Training Data**:  \n",
    "  The `train.json` file is read and converted into a pandas DataFrame (`train_df`). This dataset contains labeled recipes with their corresponding cuisines.\n",
    "\n",
    "- **Test Data**:  \n",
    "  The `test.json` file is read and converted into a pandas DataFrame (`test_df`). This dataset contains unlabeled recipes that need to be classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771acc1d-018d-4ed4-a273-43e0335f49a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../src/input/train.json', 'r') as f:\n",
    "    cuisine_train = json.load(f)\n",
    "train_df = pd.DataFrame(cuisine_train)\n",
    "\n",
    "with open('../src/input/test.json', 'r') as f:\n",
    "    cuisine_test = json.load(f)\n",
    "test_df = pd.DataFrame(cuisine_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fe5f88-c2c5-4227-b066-c22261725da3",
   "metadata": {},
   "source": [
    "This function creates an interactive table using Plotly, with customizable data, title, and maximum rows, featuring color-coded headers and cells for enhanced readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f4a533-255e-4be0-9b26-33897af34c62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da50b987-2fb3-427f-a91e-5088e68e23eb",
   "metadata": {},
   "source": [
    "## Data Tables\n",
    "\n",
    "- **Training Data**: Makes and shows table of all training data\n",
    "- **Test Data**: Makes and shows table of all test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0924fd-3565-4bc1-a5d1-f3b7947b4729",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_table = create_interactive_table(train_df.head(20), \"Training Data (All Records)\")\n",
    "train_table.show()\n",
    "\n",
    "test_table = create_interactive_table(test_df.head(20), \"Test Data (All Records)\")\n",
    "test_table.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6f645f-9fe4-404a-9661-43bf69ee8d47",
   "metadata": {},
   "source": [
    "## Data Info Tables\n",
    "Summary tables for training and test data, showing column details and non-null counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c1702c-a684-473a-91da-dbe93f68ffa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#training data table information\n",
    "train_info_df = create_info_df(train_df)\n",
    "train_info_table = create_interactive_table(train_info_df, \"Information about Training Data\")\n",
    "train_info_table.show()\n",
    "\n",
    "#test data table information\n",
    "test_info_df = create_info_df(test_df)\n",
    "test_info_table = create_interactive_table(test_info_df, \"Information about Test Data\")\n",
    "test_info_table.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b3c1b3-4331-43c6-af23-31279d6ee075",
   "metadata": {},
   "source": [
    "## Missing Values Analysis\n",
    "Showing the count and percentage of missing values in both training and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4204c45-0ce9-4da5-a780-7efec555a882",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "missing_values_df = create_missing_values_df(train_df, test_df)\n",
    "missing_values_table = create_interactive_table(missing_values_df, \"Missing Values in Training and Test Data\")\n",
    "missing_values_table.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586e6661-c67f-4277-9b58-ab17103569b9",
   "metadata": {},
   "source": [
    "## Cuisine Distribution Analysis\n",
    "Showing the count and percentage of each unique cuisine in the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe2417f-8db8-4d3d-b456-03487b518f59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "653c072e-dd0e-4728-8803-be06e85fc379",
   "metadata": {},
   "source": [
    "## Cuisine Distribution Visualization\n",
    "Bar chart showing the distribution of different cuisines in the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9a3951-6d1d-4e89-855f-0d9fd48eb849",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "train_df['cuisine'].value_counts().plot(kind='bar')\n",
    "plt.title('Distribution of Cuisines')\n",
    "plt.xlabel('Cuisine')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7817cfc0-e8a0-42d9-9afe-fb319d6b4e77",
   "metadata": {},
   "source": [
    "## Ingredients Count Distribution\n",
    "Histogram showing the distribution of the number of ingredients per recipe in the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6553d89e-548e-46f0-8db9-f1ff68a25081",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "train_df['ingredients'].apply(len).hist(bins=20)\n",
    "plt.title('Distribution of Number of Ingredients per Recipe')\n",
    "plt.xlabel('Number of Ingredients')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00f5a4d-fade-4252-88cc-7dd864057214",
   "metadata": {},
   "source": [
    "## Top 10 Ingredients Visualization\n",
    "Bar chart showing the top 10 most common ingredients in the training dataset along with their frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d2c08b-4410-4711-a5ac-cadb937ae06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ingredients = [item for sublist in train_df['ingredients'] for item in sublist]\n",
    "ingredient_freq = Counter(all_ingredients)\n",
    "top_10 = dict(ingredient_freq.most_common(10))\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(top_10.keys(), top_10.values())\n",
    "plt.title('Top 10 Most Common Ingredients')\n",
    "plt.xlabel('Ingredient')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7553921a-9d3d-47cc-8bbd-761ea3f74eba",
   "metadata": {},
   "source": [
    "## Average Ingredients by Cuisine\n",
    "Bar chart showing the average number of ingredients used in recipes for each cuisine type in the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a150be1-ca1f-45d9-955b-fc8676abff03",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_ingredients = train_df.groupby('cuisine')['ingredients'].apply(lambda x: np.mean([len(i) for i in x])).sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "avg_ingredients.plot(kind='bar')\n",
    "plt.title('Average Number of Ingredients by Cuisine')\n",
    "plt.xlabel('Cuisine')\n",
    "plt.ylabel('Average Number of Ingredients')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9566a9-7db6-4c02-b317-ca2143c71d5b",
   "metadata": {},
   "source": [
    "## Top 10 Ingredients Analysis\n",
    "Showing the rank, name, frequency, and percentage of the top 10 most common ingredients in the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc20bdc0-deaf-4c67-bfcf-c6ee1e8badd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0896884-1fa6-42d1-a86b-df4983a92041",
   "metadata": {},
   "source": [
    "## Average Ingredients by Cuisine Table\n",
    "Ranking cuisines based on their average number of ingredients per recipe in the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31907827-b3be-4a1c-bafd-aece1cde414b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d162d628-8ca6-4f95-809c-4a4ffc624a00",
   "metadata": {},
   "source": [
    "## Ingredient String Creation\n",
    "Combines ingredient lists into single strings for both training and test datasets to prepare for text processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b568bb-1a7d-408b-8119-78459d40a19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['ingredients_str'] = train_df['ingredients'].apply(lambda x: ' '.join(x))\n",
    "test_df['ingredients_str'] = test_df['ingredients'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23aaf311-cec9-4086-9028-fecbfacc6fe3",
   "metadata": {},
   "source": [
    "## Ingredient Processing Visualization\n",
    "Showing the original ingredient lists and their processed string versions for both training and test datasets (first 10 rows each)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33113a0d-3eac-475f-976f-c20c652ad6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df\n",
    "train_table = create_interactive_table(train_df[['ingredients', 'ingredients_str']].head(10), \"Train Data: Original vs Processed Ingredients\")\n",
    "train_table.show()\n",
    "\n",
    "#test_df\n",
    "test_table = create_interactive_table(test_df[['ingredients', 'ingredients_str']].head(10), \"Test Data: Original vs Processed Ingredients\")\n",
    "test_table.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43387ddd-3f50-41e2-aa51-4cb04ba55b29",
   "metadata": {},
   "source": [
    "## Recipe Data Processing and Analysis\n",
    "\n",
    "Displaying initial raw recipe data, processing ingredients into strings, and filtering out entries with empty ingredients.\n",
    "\n",
    "Displaying of the processed and filtered dataset, followed by a table showing the 20 most common ingredients across all recipes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52a20bd-2a6e-433e-9695-00cef7614d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "recipes_df = pd.read_csv('../src/input/predicted_ingredients.csv')\n",
    "\n",
    "recipes_before_table = create_interactive_table(recipes_df.head(10), \"Recipes Data: Before Processing\")\n",
    "recipes_before_table.show()\n",
    "\n",
    "\n",
    "recipes_df['ingredients_str'] = recipes_df['predicted_ingredients'].apply(process_set_string)\n",
    "\n",
    "recipes_after_table = create_interactive_table(recipes_df[['predicted_ingredients', 'ingredients_str']].head(10), \"Recipes Data: After Processing\")\n",
    "recipes_after_table.show()\n",
    "\n",
    "\n",
    "recipes_df = recipes_df[recipes_df['ingredients_str'] != \"\"]\n",
    "\n",
    "recipes_final_table = create_interactive_table(recipes_df.head(10), \"Recipes Data: Final (After Filtering)\")\n",
    "recipes_final_table.show()\n",
    "\n",
    "\n",
    "all_ingredients = ' '.join(recipes_df['ingredients_str']).split()\n",
    "ingredient_freq = Counter(all_ingredients).most_common(20)\n",
    "ingredient_freq_df = pd.DataFrame(ingredient_freq, columns=['Ingredient', 'Frequency'])\n",
    "ingredient_freq_table = create_interactive_table(ingredient_freq_df, \"Top 20 Most Common Ingredients\")\n",
    "ingredient_freq_table.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220a1ffe-6f24-48fe-8e68-677a90bf0479",
   "metadata": {},
   "source": [
    "## Data Splitting and Distribution Analysis\n",
    "\n",
    "1. **Data Split**: \n",
    "   - Training set: 80% of data\n",
    "   - Validation set: 20% of data\n",
    "\n",
    "2. **Sample Display**:\n",
    "   - Shows first 10 rows of both training and validation sets\n",
    "\n",
    "3. **Cuisine Distribution**:\n",
    "   - Creates a table showing the count and percentage of each cuisine in both sets\n",
    "\n",
    "4. **Dataset Size Summary**:\n",
    "   - Prints total, training, and validation sample counts with percentages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c249f8-09c1-498d-b94a-087a90fa598c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    train_df['ingredients_str'],\n",
    "    train_df['cuisine'],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=train_df['cuisine']\n",
    ")\n",
    "\n",
    "train_data = pd.DataFrame({'ingredients_str': X_train, 'cuisine': y_train}).reset_index(drop=True)\n",
    "val_data = pd.DataFrame({'ingredients_str': X_val, 'cuisine': y_val}).reset_index(drop=True)\n",
    "\n",
    "train_table = create_interactive_table(train_data.head(10), \"Training Data Sample (First 10 rows)\")\n",
    "train_table.show()\n",
    "\n",
    "val_table = create_interactive_table(val_data.head(10), \"Validation Data Sample (First 10 rows)\")\n",
    "val_table.show()\n",
    "\n",
    "train_cuisine_dist = y_train.value_counts().reset_index()\n",
    "train_cuisine_dist.columns = ['Cuisine', 'Count in Training']\n",
    "val_cuisine_dist = y_val.value_counts().reset_index()\n",
    "val_cuisine_dist.columns = ['Cuisine', 'Count in Validation']\n",
    "\n",
    "cuisine_dist = pd.merge(train_cuisine_dist, val_cuisine_dist, on='Cuisine', how='outer').fillna(0)\n",
    "cuisine_dist['Training Percentage'] = (cuisine_dist['Count in Training'] / len(y_train) * 100).round(2)\n",
    "cuisine_dist['Validation Percentage'] = (cuisine_dist['Count in Validation'] / len(y_val) * 100).round(2)\n",
    "\n",
    "cuisine_dist_table = create_interactive_table(cuisine_dist, \"Distribution of Cuisines in Training and Validation Sets\")\n",
    "cuisine_dist_table.show()\n",
    "\n",
    "print(f\"Total samples: {len(train_df)}\")\n",
    "print(f\"Training samples: {len(X_train)} ({len(X_train)/len(train_df)*100:.2f}%)\")\n",
    "print(f\"Validation samples: {len(X_val)} ({len(X_val)/len(train_df)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afc0209-4d3d-40cb-8f5d-d430f8da6f19",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "Three machine learning models are trained on the preprocessed data:\n",
    "\n",
    "1. **Random Forest**:\n",
    "   - Uses CountVectorizer for text preprocessing\n",
    "   - 100 trees in the forest\n",
    "\n",
    "2. **Gradient Boosting**:\n",
    "   - Uses CountVectorizer for text preprocessing\n",
    "   - 100 boosting stages\n",
    "\n",
    "3. **Support Vector Machine (SVM)**:\n",
    "   - Uses TfidfVectorizer for text preprocessing\n",
    "   - Linear SVM with probability calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df0c57e-d3f1-4555-903b-9aca74e0c4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(analyzer='word', ngram_range=(1, 2))),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1))\n",
    "])\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "\n",
    "gb_pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(analyzer='word', ngram_range=(1, 2))),\n",
    "    ('classifier', GradientBoostingClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "gb_pipeline.fit(X_train, y_train)\n",
    "\n",
    "svc_pipeline = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(analyzer='word', ngram_range=(1, 2))),\n",
    "    ('classifier', CalibratedClassifierCV(LinearSVC(random_state=42, max_iter=1000), method='sigmoid'))\n",
    "])\n",
    "svc_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abb3587-46dd-4632-8c84-105c8ee63bae",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "  **Performance Comparison**:\n",
    "   - Creating a table comparing the performance metrics (precision, recall, F1-score) for Random Forest, Gradient Boosting, and SVM models on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739c3bed-d465-4b16-8724-bb4f5f6abeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#performance DataFrames\n",
    "rf_performance = create_model_performance_df(rf_pipeline, X_val, y_val, 'Random Forest')\n",
    "gb_performance = create_model_performance_df(gb_pipeline, X_val, y_val, 'Gradient Boosting')\n",
    "svc_performance = create_model_performance_df(svc_pipeline, X_val, y_val, 'SVC')\n",
    "\n",
    "# Combine performances\n",
    "all_performance = pd.concat([rf_performance, gb_performance, svc_performance])\n",
    "\n",
    "#model performances\n",
    "performance_table = create_interactive_table(all_performance, \"Model Performance Comparison\")\n",
    "performance_table.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0aebdf-9a15-44fe-8e92-edda969bc815",
   "metadata": {},
   "source": [
    "## Probability Predictions\n",
    "\n",
    "Generates probability predictions for each model:\n",
    "\n",
    "1. Random Forest (rf_probs)\n",
    "2. Gradient Boosting (gb_probs)\n",
    "3. Support Vector Machine (svc_probs)\n",
    "\n",
    "These probabilities represent the model's confidence in classifying each cuisine type for the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a38234f-8854-42cf-b8d0-ecae75516c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_probs = rf_pipeline.predict_proba(X_val)\n",
    "gb_probs = gb_pipeline.predict_proba(X_val)\n",
    "svc_probs = svc_pipeline.predict_proba(X_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bfefef-4544-4ef7-bc6d-2ecbd44ef84f",
   "metadata": {},
   "source": [
    "## ROC Curve Visualization\n",
    "\n",
    "Creating ROC (Receiver Operating Characteristic) curve plot:\n",
    "\n",
    "- Shows curves for Random Forest, Gradient Boosting, and SVM models\n",
    "- Includes AUC (Area Under Curve) scores for each model\n",
    "- Compares model performance against random guessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49985f8-126c-4555-a562-4a2f634ed8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ROC curves\n",
    "roc_fig = plot_roc_curves(y_val, [rf_probs, gb_probs, svc_probs], ['Random Forest', 'Gradient Boosting', 'SVC'])\n",
    "roc_fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4939505d-a2a6-4e21-9ffa-15679d9adfed",
   "metadata": {},
   "source": [
    "## Ensemble Model Predictions\n",
    "\n",
    "Combines prediction probabilities from multiple models (Random Forest, Gradient Boosting, SVM) by averaging, then determines the predicted class for each sample based on the highest probability.\n",
    "\n",
    "The predicted class indices are then decoded back to cuisine labels using a LabelEncoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e4b4f7-2c21-4c34-893b-c784731b8d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_probs = (rf_probs + gb_probs + svc_probs) / 3\n",
    "ensemble_pred_classes = np.argmax(ensemble_probs, axis=1)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(train_df['cuisine'])\n",
    "ensemble_pred_labels = label_encoder.inverse_transform(ensemble_pred_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08af4229-0940-455a-a032-a0d65adbd377",
   "metadata": {},
   "source": [
    "## Ensemble Model Evaluation\n",
    "\n",
    "Box plot of prediction probabilities, a confusion matrix heatmap, and a classification report table for the ensemble model.\n",
    "\n",
    "These visualizations and metrics provide insights into the model's confidence across cuisines, its accuracy in predictions, and detailed performance metrics for each cuisine class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da249c8-e055-4b95-a9ba-76f4b8b3498c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plot_ensemble_probabilities(ensemble_probs, label_encoder)\n",
    "\n",
    "\n",
    "\n",
    "plot_confusion_matrix(y_val, ensemble_pred_labels, label_encoder.classes_)\n",
    "\n",
    "\n",
    "plot_classification_report(y_val, ensemble_pred_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82aca992-8382-4383-896b-046e33afef00",
   "metadata": {},
   "source": [
    "## Ensemble Model Performance and Visualizations\n",
    "\n",
    "Validation accuracy, classification report, confusion matrix heatmap, cuisine distribution charts, model comparison, and feature importance visualization for the ensemble model.\n",
    "\n",
    "These visualizations provide comprehensive insights into model performance, prediction patterns, and key factors influencing cuisine classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ade2df-615f-40ba-b395-0e01fd3731db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cuisine Distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "train_df['cuisine'].value_counts().plot(kind=\"bar\")\n",
    "plt.title(\"Distribution of Cuisines in Training Data\")\n",
    "plt.xlabel(\"Cuisine\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#Cuisine Distribution\n",
    "pred_counts = pd.Series(ensemble_pred_labels).value_counts()\n",
    "fig_pie = px.pie(\n",
    "    names=pred_counts.index,\n",
    "    values=pred_counts.values,\n",
    "    title=\"Predicted Cuisine Distribution (Validation Set)\",\n",
    "    hole=0.3\n",
    ")\n",
    "fig_pie.update_traces(textinfo='value+percent')\n",
    "fig_pie.update_layout(\n",
    "    autosize=False,\n",
    "    width=800,  \n",
    "    height=600, \n",
    "    margin=dict(l=20, r=20, t=100, b=20) \n",
    ")\n",
    "fig_pie.show()\n",
    "\n",
    "# Model Comparison\n",
    "model_probs_df = pd.DataFrame({\n",
    "    \"Cuisine\": label_encoder.classes_,\n",
    "    \"Random Forest\": rf_probs.mean(axis=0),\n",
    "    \"Gradient Boosting\": gb_probs.mean(axis=0),\n",
    "    \"Linear SVC\": svc_probs.mean(axis=0),\n",
    "    \"Ensemble\": ensemble_probs.mean(axis=0)\n",
    "})\n",
    "plt.figure(figsize=(12, 6))\n",
    "model_probs_df.set_index(\"Cuisine\").plot(kind=\"bar\")\n",
    "plt.title(\"Average Probability Predictions by Model (Validation Set)\")\n",
    "plt.ylabel(\"Average Probability\")\n",
    "plt.xlabel(\"Cuisine\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e5132c-c7f9-4cc1-a398-8431d3fe910e",
   "metadata": {},
   "source": [
    "## Model Training and Saving\n",
    "\n",
    "Random Forest, Gradient Boosting, and Linear SVC models were trained on the full training dataset and saved as separate pickle files.\n",
    "\n",
    "The Label Encoder used for cuisine encoding was also saved as a pickle file for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4042986-3839-4534-80c5-90f4431a841c",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_FOREST_MODEL_FILE = 'randomforest_model.pkl'\n",
    "GRADIENT_BOOSTING_MODEL_FILE = 'gradientboosting_model.pkl'\n",
    "LINEAR_SVC_MODEL_FILE = 'linearsvc_model.pkl'\n",
    "LABEL_ENCODER_FILE = 'label_encoder.pkl'\n",
    "\n",
    "rf_pipeline.fit(train_df['ingredients_str'], train_df['cuisine'])\n",
    "joblib.dump(rf_pipeline, RANDOM_FOREST_MODEL_FILE)\n",
    "\n",
    "gb_pipeline.fit(train_df['ingredients_str'], train_df['cuisine'])\n",
    "joblib.dump(gb_pipeline, GRADIENT_BOOSTING_MODEL_FILE)\n",
    "\n",
    "svc_pipeline.fit(train_df['ingredients_str'], train_df['cuisine'])\n",
    "joblib.dump(svc_pipeline, LINEAR_SVC_MODEL_FILE)\n",
    "\n",
    "joblib.dump(label_encoder, LABEL_ENCODER_FILE)\n",
    "print(f\"Models saved as 'src/models/classification/{RANDOM_FOREST_MODEL_FILE}', 'src/models/classification/{GRADIENT_BOOSTING_MODEL_FILE}', 'src/models/classification/{LINEAR_SVC_MODEL_FILE}', and 'src/models/classification/{LABEL_ENCODER_FILE}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db614e5a-27ba-4948-9e2f-3adb263615fe",
   "metadata": {},
   "source": [
    "## Training Accuracy Comparison\n",
    "\n",
    "This bar chart compares the training accuracy of Random Forest, Gradient Boosting, and Linear SVC models, with the y-axis showing accuracy from 0 to 1.\n",
    "\n",
    "Observations reveal relative performance of models on the training set, with high accuracies suggesting good fit and differences indicating varying model complexity or suitability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e79b90-9f87-4d1d-b922-baafae2e8600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on training data\n",
    "rf_train_preds = rf_pipeline.predict(train_df['ingredients_str'])\n",
    "gb_train_preds = gb_pipeline.predict(train_df['ingredients_str'])\n",
    "svc_train_preds = svc_pipeline.predict(train_df['ingredients_str'])\n",
    "\n",
    "# Calculate accuracy\n",
    "rf_train_acc = accuracy_score(train_df['cuisine'], rf_train_preds)\n",
    "gb_train_acc = accuracy_score(train_df['cuisine'], gb_train_preds)\n",
    "svc_train_acc = accuracy_score(train_df['cuisine'], svc_train_preds)\n",
    "\n",
    "# Visualize training accuracy\n",
    "model_names = ['Random Forest', 'Gradient Boosting', 'Linear SVC']\n",
    "train_accuracies = [rf_train_acc, gb_train_acc, svc_train_acc]\n",
    "\n",
    "fig = px.bar(x=model_names, y=train_accuracies,\n",
    "             labels={'x': 'Model', 'y': 'Training Accuracy'},\n",
    "             title=\"Training Accuracy of Models\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4b5bf7-2bd6-460d-9b7c-298c183911c2",
   "metadata": {},
   "source": [
    "## Confusion Matrices for Model Comparison\n",
    "\n",
    "Confusion matrices for Random Forest, Gradient Boosting, and SVC models.\n",
    "\n",
    "Observations show strong diagonal elements indicating good performance, with some off-diagonal elements revealing minor misclassifications between cuisines for each model.\n",
    "\n",
    "Comparing the matrices reveals strengths and weaknesses of each model in classifying specific cuisines, with diagonal elements representing correct classifications and off-diagonal elements showing misclassifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05c36be-a5f8-4bc5-97ec-9278622f023c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix for Random Forest\n",
    "rf_cm = confusion_matrix(train_df['cuisine'], rf_train_preds)\n",
    "fig_rf_cm = go.Figure(data=go.Heatmap(z=rf_cm,\n",
    "                                      x=label_encoder.classes_,\n",
    "                                      y=label_encoder.classes_,\n",
    "                                      colorscale='Blues'))\n",
    "fig_rf_cm.update_layout(title=\"Confusion Matrix - Random Forest\",\n",
    "                        xaxis_title=\"Predicted\",\n",
    "                        yaxis_title=\"Actual\")\n",
    "fig_rf_cm.show()\n",
    "\n",
    "# Confusion matrix for Gradient Boosting\n",
    "gb_cm = confusion_matrix(train_df['cuisine'], gb_train_preds)\n",
    "fig_rf_cm = go.Figure(data=go.Heatmap(z=gb_cm,\n",
    "                                      x=label_encoder.classes_,\n",
    "                                      y=label_encoder.classes_,\n",
    "                                      colorscale='Blues'))\n",
    "fig_rf_cm.update_layout(title=\"Confusion Matrix - Gradient Boosting\",\n",
    "                        xaxis_title=\"Predicted\",\n",
    "                        yaxis_title=\"Actual\")\n",
    "fig_rf_cm.show()\n",
    "\n",
    "# Confusion matrix for Svc\n",
    "svc_cm = confusion_matrix(train_df['cuisine'], svc_train_preds)\n",
    "fig_rf_cm = go.Figure(data=go.Heatmap(z=svc_cm,\n",
    "                                      x=label_encoder.classes_,\n",
    "                                      y=label_encoder.classes_,\n",
    "                                      colorscale='Blues'))\n",
    "fig_rf_cm.update_layout(title=\"Confusion Matrix - Svc\",\n",
    "                        xaxis_title=\"Predicted\",\n",
    "                        yaxis_title=\"Actual\")\n",
    "fig_rf_cm.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2834d9-e3c6-435c-94e2-d5d24b7c8f13",
   "metadata": {},
   "source": [
    "## Test Set Predictions and Analysis\n",
    "\n",
    "Combining ensemble predictions from multiple models to classify cuisines in the test set, with results saved to a CSV file.\n",
    "\n",
    "A bar chart visualizes the distribution of predicted cuisines, revealing insights into prediction balance and potential biases.\n",
    "\n",
    "Observations from the chart can indicate model performance and dataset characteristics, highlighting any significant imbalances in cuisine predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a7f495-e8fa-4909-bf63-2227e23b98ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_test_probs = rf_pipeline.predict_proba(test_df['ingredients_str'])\n",
    "gb_test_probs = gb_pipeline.predict_proba(test_df['ingredients_str'])\n",
    "svc_test_probs = svc_pipeline.predict_proba(test_df['ingredients_str'])\n",
    "ensemble_test_probs = (rf_test_probs + gb_test_probs + svc_test_probs) / 3\n",
    "test_pred_classes = np.argmax(ensemble_test_probs, axis=1)\n",
    "test_df['predicted_cuisine'] = label_encoder.inverse_transform(test_pred_classes)\n",
    "test_df[['id', 'predicted_cuisine']].to_csv('ensemble_test_predictions.csv', index=False)\n",
    "\n",
    "#Predicted Cuisine Distribution (Test Set)\n",
    "plt.figure(figsize=(10, 6))\n",
    "test_df['predicted_cuisine'].value_counts().plot(kind=\"bar\")\n",
    "plt.title(\"Distribution of Predicted Cuisines (Test Set)\")\n",
    "plt.xlabel(\"Cuisine\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6515f460-3208-46e8-93ae-8c8e98a7a90c",
   "metadata": {},
   "source": [
    "## Comprehensive Test Set Analysis\n",
    "\n",
    "Predicted cuisine distribution, top confident predictions, prediction confidence distribution, model agreement, and a word cloud of ingredients, providing insights into the model's performance and dataset characteristics.\n",
    "\n",
    "- This reveal frequently predicted cuisines, high-confidence predictions, overall model certainty, inter-model agreement, and dominant ingredients.\n",
    "- These insights help identify potential biases, assess model reliability, and understand key factors in cuisine classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf0b6a5-ca4a-4d3c-9bfc-d3ddaa12ead0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Predicted Cuisines\n",
    "\n",
    "pred_cuisine_counts = test_df['predicted_cuisine'].value_counts()\n",
    "fig = px.pie(values=pred_cuisine_counts.values, names=pred_cuisine_counts.index, \n",
    "             title='Distribution of Predicted Cuisines', hole=0.3)\n",
    "fig.update_layout(width=800, height=600)\n",
    "fig.show()\n",
    "\n",
    "#Prediction Confidence Distribution\n",
    "test_df['max_probability'] = np.max(ensemble_test_probs, axis=1)\n",
    "fig = px.histogram(test_df, x='max_probability', nbins=50,\n",
    "                   title='Distribution of Prediction Confidence')\n",
    "fig.update_layout(width=800, height=600)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "\n",
    "agreement_matrix = np.array([\n",
    "    [1, model_agreement(rf_test_probs, gb_test_probs), model_agreement(rf_test_probs, svc_test_probs)],\n",
    "    [model_agreement(gb_test_probs, rf_test_probs), 1, model_agreement(gb_test_probs, svc_test_probs)],\n",
    "    [model_agreement(svc_test_probs, rf_test_probs), model_agreement(svc_test_probs, gb_test_probs), 1]\n",
    "])\n",
    "\n",
    "fig = go.Figure(data=go.Heatmap(\n",
    "                z=agreement_matrix,\n",
    "                x=['Random Forest', 'Gradient Boosting', 'SVC'],\n",
    "                y=['Random Forest', 'Gradient Boosting', 'SVC'],\n",
    "                colorscale='Viridis'))\n",
    "fig.update_layout(title='Model Agreement Heatmap', width=800, height=600)\n",
    "fig.show()\n",
    "\n",
    "#Ingredients Word Cloud (if you have wordcloud installed)\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "all_ingredients = ' '.join(test_df['ingredients_str'])\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white', max_words=100).generate(all_ingredients)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Word Cloud of Ingredients in Test Set')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84273385-1fed-45b1-80c5-ade987b1a5b9",
   "metadata": {},
   "source": [
    "## Analysis of Predicted Cuisines for Recipes Dataset\n",
    "\n",
    "Distribution of predicted cuisines for the recipes dataset using the ensemble model.\n",
    "\n",
    "- The chart reveals which cuisines are most commonly predicted in the recipes dataset.\n",
    "- It helps identify any potential biases or imbalances in the predictions.\n",
    "- The distribution can be compared with that of the training data to check for consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfb329a-b9ca-432f-87b9-a5dc541b383f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_recipes_probs = rf_pipeline.predict_proba(recipes_df['ingredients_str'])\n",
    "gb_recipes_probs = gb_pipeline.predict_proba(recipes_df['ingredients_str'])\n",
    "svc_recipes_probs = svc_pipeline.predict_proba(recipes_df['ingredients_str'])\n",
    "ensemble_recipes_probs = (rf_recipes_probs + gb_recipes_probs + svc_recipes_probs) / 3\n",
    "recipes_pred_classes = np.argmax(ensemble_recipes_probs, axis=1)\n",
    "recipes_df['predicted_cuisine'] = label_encoder.inverse_transform(recipes_pred_classes)\n",
    "recipes_df.to_csv('ensemble_recipes_with_cuisines.csv', index=False)\n",
    "\n",
    "#Predicted Cuisine Distribution (Recipes Data)\n",
    "recipes_counts = recipes_df['predicted_cuisine'].value_counts()\n",
    "fig_recipes_pie = px.pie(\n",
    "    names=recipes_counts.index,\n",
    "    values=recipes_counts.values,\n",
    "    title=\"Predicted Cuisine Distribution (Recipes Dataset)\",\n",
    "    hole=0.3\n",
    ")\n",
    "fig_recipes_pie.update_layout(width=800, height=600)\n",
    "fig_recipes_pie.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcb946b-b6d9-4d11-b973-92f75fea307b",
   "metadata": {},
   "source": [
    "## Predicted Cuisine Distribution for Recipes Dataset (Bar Chart)\n",
    "\n",
    "Distribution of predicted cuisines for the recipes dataset, offering a different perspective from the previous pie chart.\n",
    "\n",
    "- The chart clearly shows the relative frequency of each predicted cuisine.\n",
    "- It allows for easy comparison of counts between different cuisines.\n",
    "- The height of each bar directly corresponds to the number of recipes predicted for that cuisine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3a5ab2-cc79-42b6-8af9-c5dc7f066705",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_bar = px.bar(\n",
    "    x=recipes_counts.index,\n",
    "    y=recipes_counts.values,\n",
    "    labels={'x': 'Cuisine', 'y': 'Count'},\n",
    "    title=\"Predicted Cuisine Distribution (Recipes Dataset)\"\n",
    ")\n",
    "fig_bar.update_layout(width=800, height=600)\n",
    "fig_bar.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71acefa5-9d2f-4ea2-9f44-859f36476738",
   "metadata": {},
   "source": [
    "## Top 5 Predicted Cuisines for Recipes Dataset (Bar Chart)\n",
    "\n",
    "Five most frequently predicted cuisines in the recipes dataset, providing a more detailed look at the dominant categories.\n",
    "\n",
    "- The chart clearly highlights the most common cuisine predictions in the dataset.\n",
    "- It allows for easy comparison between the top predicted cuisines.\n",
    "- The height of each bar directly corresponds to the number of recipes predicted for that cuisine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dcf372-b072-4585-9a46-1f8176fb435b",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_cuisines = recipes_counts.head(5)  # Top 5 cuisines\n",
    "fig_top_cuisines = px.bar(\n",
    "    x=top_cuisines.index,\n",
    "    y=top_cuisines.values,\n",
    "    labels={'x': 'Cuisine', 'y': 'Count'},\n",
    "    title=\"Top 5 Predicted Cuisines (Recipes Dataset)\"\n",
    ")\n",
    "fig_top_cuisines.update_layout(width=800, height=600)\n",
    "fig_top_cuisines.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45ccd54-f481-45a2-8202-d4ff3265b6a8",
   "metadata": {},
   "source": [
    "## Prediction Confidence Analysis\n",
    "1. **Confidence Distribution**: The histogram shows how prediction confidence scores are distributed across the recipes dataset.\n",
    "2. **Model Certainty**: Peaks in the distribution indicate common confidence levels, while the spread reveals variability in model certainty.\n",
    "3. **Insights for Improvement**: This visualization helps identify reliable predictions and areas where the model may need refinement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a003e9-f01e-4e23-b50a-b51f28de0153",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes_df['max_probability'] = np.max(ensemble_recipes_probs, axis=1)\n",
    "fig_confidence = px.histogram(\n",
    "    recipes_df,\n",
    "    x='max_probability',\n",
    "    nbins=50,\n",
    "    title='Distribution of Prediction Confidence (Recipes Dataset)',\n",
    "    labels={'max_probability': 'Prediction Confidence'}\n",
    ")\n",
    "fig_confidence.update_layout(width=800, height=600)\n",
    "fig_confidence.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034c47c5-d0d9-444d-8a1c-5e27d0a69ebc",
   "metadata": {},
   "source": [
    "## Model Testing and Visualization\n",
    "\n",
    "loads trained models, tests them on predefined examples.\n",
    "    \n",
    "The script concludes with a detailed breakdown of top 5 predictions for each example and a summary of overall prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd7b41d-915a-43c1-8709-95faca7c64d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Loading the trained models\n",
    "rf_pipeline = joblib.load('randomforest_model.pkl')\n",
    "gb_pipeline = joblib.load('gradientboosting_model.pkl')\n",
    "svc_pipeline = joblib.load('linearsvc_model.pkl')\n",
    "label_encoder = joblib.load('label_encoder.pkl')\n",
    "\n",
    "# test examples\n",
    "test_examples = [\n",
    "    {\"ingredients\": [\"rice\", \"soy sauce\", \"ginger\", \"garlic\", \"green onion\"], \"expected\": \"Chinese\"},\n",
    "    {\"ingredients\": [\"pasta\", \"tomato sauce\", \"olive oil\", \"basil\", \"parmesan\"], \"expected\": \"Italian\"},\n",
    "    {\"ingredients\": [\"tortilla\", \"beans\", \"chili pepper\", \"lime\", \"cilantro\"], \"expected\": \"Mexican\"},\n",
    "    {\"ingredients\": [\"rice\", \"curry powder\", \"turmeric\", \"cumin\", \"yogurt\"], \"expected\": \"Indian\"},\n",
    "    {\"ingredients\": [\"butter\", \"cream\", \"wine\", \"thyme\", \"shallots\"], \"expected\": \"French\"}\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Test each example and store results\n",
    "results = []\n",
    "for example in test_examples:\n",
    "    ingredients = example[\"ingredients\"]\n",
    "    expected = example[\"expected\"]\n",
    "    predicted_cuisine, confidence, ensemble_probs = predict_cuisine(\n",
    "        ingredients, rf_pipeline, gb_pipeline, svc_pipeline, label_encoder\n",
    "    )\n",
    "    correct = predicted_cuisine.lower() == expected.lower()  \n",
    "    results.append({\n",
    "        \"Ingredients\": ', '.join(ingredients),\n",
    "        \"Expected Cuisine\": expected,\n",
    "        \"Predicted Cuisine\": predicted_cuisine,\n",
    "        \"Confidence\": round(confidence, 6),  \n",
    "        \"Correct\": correct\n",
    "    })\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "results_table = create_interactive_table(results_df, \"Test Results for Known Examples\")\n",
    "results_table.show()\n",
    "\n",
    "# predictions with confidence\n",
    "fig_bar = px.bar(results_df, x='Ingredients', y='Confidence', color='Correct',\n",
    "                 text=results_df['Predicted Cuisine'],\n",
    "                 title='Predicted Cuisines for Known Examples with Confidence',\n",
    "                 labels={'Confidence': 'Prediction Confidence'},\n",
    "                 height=600, width=1000)\n",
    "fig_bar.update_traces(textposition='auto')\n",
    "fig_bar.add_hline(y=0.5, line_dash=\"dash\", line_color=\"gray\", annotation_text=\"Confidence Threshold (0.5)\")\n",
    "fig_bar.update_layout(xaxis={'tickangle': 45})\n",
    "fig_bar.show()\n",
    "\n",
    "#Detailed probabilities for each example\n",
    "for i, example in enumerate(test_examples):\n",
    "    _, _, ensemble_probs = predict_cuisine(example[\"ingredients\"], rf_pipeline, gb_pipeline, svc_pipeline, label_encoder)\n",
    "    top_5_indices = np.argsort(ensemble_probs)[::-1][:5]\n",
    "    top_5_cuisines = label_encoder.inverse_transform(top_5_indices)\n",
    "    top_5_probs = ensemble_probs[top_5_indices]\n",
    "    \n",
    "    top_5_df = pd.DataFrame({'Cuisine': top_5_cuisines, 'Probability': top_5_probs})\n",
    "    fig_detail = px.bar(top_5_df, x='Cuisine', y='Probability',\n",
    "                        title=f'Top 5 Predictions for: {\", \".join(example[\"ingredients\"])} (Expected: {example[\"expected\"]})',\n",
    "                        text=top_5_df['Probability'].round(4))\n",
    "    fig_detail.update_traces(textposition='auto')\n",
    "    fig_detail.update_layout(width=800, height=500)\n",
    "    fig_detail.show()\n",
    "\n",
    "# Summary\n",
    "correct_count = results_df['Correct'].sum()\n",
    "total_tests = len(results_df)\n",
    "print(f\"\\nSummary: {correct_count}/{total_tests} predictions correct ({correct_count/total_tests*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ff1536-7de2-44cd-8f36-5f644d0897a3",
   "metadata": {},
   "source": [
    "## Batch Cuisine Prediction and Analysis\n",
    "\n",
    "loading trained models, processing the recipes dataset, and making batch predictions using an ensemble approach.\n",
    "\n",
    "The final combined results are saved as `recipes_with_predicted_cuisines.csv`, accompanied by summary statistics on prediction confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2d2484-1787-4930-b196-3f4280cb2f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import ast\n",
    "from tqdm import tqdm  # For progress bar\n",
    "\n",
    "# Loading trained models\n",
    "rf_pipeline = joblib.load('randomforest_model.pkl')\n",
    "gb_pipeline = joblib.load('gradientboosting_model.pkl')\n",
    "svc_pipeline = joblib.load('linearsvc_model.pkl')\n",
    "label_encoder = joblib.load('label_encoder.pkl')\n",
    "\n",
    "# Loading dataset\n",
    "recipes_df = pd.read_csv('../src/input/predicted_ingredients.csv')\n",
    "\n",
    "\n",
    "recipes_df['ingredients_str'] = recipes_df['predicted_ingredients'].apply(process_set_string)\n",
    "recipes_df = recipes_df[recipes_df['ingredients_str'] != \"\"]\n",
    "\n",
    "\n",
    "\n",
    "# Batch processing\n",
    "batch_size = 10000  \n",
    "results = []\n",
    "for start in tqdm(range(0, len(recipes_df), batch_size), desc=\"Processing batches\"):\n",
    "    end = min(start + batch_size, len(recipes_df))\n",
    "    batch_df = recipes_df.iloc[start:end]\n",
    "    ingredients_batch = batch_df['ingredients_str'].tolist()\n",
    "    \n",
    "    predicted_cuisines, confidences = predict_cuisine_batch(\n",
    "        ingredients_batch, rf_pipeline, gb_pipeline, svc_pipeline, label_encoder\n",
    "    )\n",
    "    \n",
    "    batch_results = pd.DataFrame({\n",
    "        \"Ingredients\": ingredients_batch,\n",
    "        \"Predicted Cuisine\": predicted_cuisines,\n",
    "        \"Confidence\": confidences.round(6)\n",
    "    })\n",
    "    results.append(batch_results)\n",
    "    \n",
    "\n",
    "    batch_results.to_csv(f'recipes_with_predicted_cuisines_batch_{start}.csv', index=False)\n",
    "\n",
    "\n",
    "results_df = pd.concat(results, ignore_index=True)\n",
    "\n",
    "# (first 50 rows)\n",
    "results_table = create_interactive_table(results_df, \"Predicted Cuisines for Recipes Dataset\", max_rows=50)\n",
    "results_table.show()\n",
    "\n",
    "# cuisine distribution\n",
    "cuisine_counts = results_df['Predicted Cuisine'].value_counts().reset_index()\n",
    "cuisine_counts.columns = ['Cuisine', 'Count']\n",
    "fig_dist = px.bar(cuisine_counts, x='Cuisine', y='Count',\n",
    "                  title='Distribution of Predicted Cuisines in Recipes Dataset',\n",
    "                  text=cuisine_counts['Count'],\n",
    "                  height=600, width=1000)\n",
    "fig_dist.update_traces(textposition='auto')\n",
    "fig_dist.update_layout(xaxis={'tickangle': 45})\n",
    "fig_dist.show()\n",
    "\n",
    "#Confidence distribution histogram\n",
    "fig_conf = px.histogram(results_df, x='Confidence', nbins=50,\n",
    "                        title='Distribution of Prediction Confidence Scores',\n",
    "                        height=600, width=1000)\n",
    "fig_conf.update_layout(bargap=0.1)\n",
    "fig_conf.show()\n",
    "\n",
    "#combined results\n",
    "results_df.to_csv('recipes_with_predicted_cuisines.csv', index=False)\n",
    "print(f\"Predictions saved to 'recipes_with_predicted_cuisines.csv'\")\n",
    "print(f\"Total recipes processed: {len(results_df)}\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(f\"Average Confidence: {results_df['Confidence'].mean():.4f}\")\n",
    "print(f\"Minimum Confidence: {results_df['Confidence'].min():.4f}\")\n",
    "print(f\"Maximum Confidence: {results_df['Confidence'].max():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb99169-017c-4744-bc72-31d9cfcc190a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
